import torch
from torch.utils.data import Dataset, DataLoader
import pandas as pd
import cv2
import numpy as np
from PIL import Image
import albumentations as A
from albumentations.pytorch import ToTensorV2
import os
import shutil
from tqdm import tqdm


class CXRDataset(Dataset):
    """èƒ¸è…” X å…‰è³‡æ–™é›†"""
    def __init__(self, df, img_dir, transform=None, is_test=False):
        self.df = df.reset_index(drop=True)
        self.img_dir = img_dir
        self.transform = transform
        self.is_test = is_test
        
    def __len__(self):
        return len(self.df)
    
    def __getitem__(self, idx):
        img_name = self.df.loc[idx, 'new_filename']
        img_path = os.path.join(self.img_dir, img_name)
        
        # è®€å–åœ–åƒ
        image = cv2.imread(img_path)
        if image is None:
            raise FileNotFoundError(f"ç„¡æ³•è®€å–åœ–åƒ: {img_path}")
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # ç›´æ–¹åœ–å‡è¡¡åŒ–ï¼ˆCLAHEï¼‰
        image = self.apply_clahe(image)
        
        # æ‡‰ç”¨è½‰æ›
        if self.transform:
            augmented = self.transform(image=image)
            image = augmented['image']
        
        if self.is_test:
            return image, img_name
        else:
            # è®€å–æ¨™ç±¤
            label = self.df.loc[idx, ['normal', 'bacteria', 'virus', 'COVID-19']].values.astype(np.float32)
            label = torch.tensor(label, dtype=torch.float32)
            # è½‰æ›ç‚º class index
            label_idx = torch.argmax(label).long()
            return image, label_idx
    
    @staticmethod
    def apply_clahe(image):
        """æ‡‰ç”¨ CLAHE æé«˜å°æ¯”åº¦"""
        lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)
        l, a, b = cv2.split(lab)
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        l = clahe.apply(l)
        lab = cv2.merge([l, a, b])
        image = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)
        return image


def get_train_transforms(img_size=384, advanced=True):
    """è¨“ç·´æ™‚çš„æ•¸æ“šå¢å¼·"""
    if advanced:
        return A.Compose([
            A.Resize(img_size, img_size),
            A.HorizontalFlip(p=0.5),
            A.Rotate(limit=15, p=0.5),
            A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.15, rotate_limit=15, p=0.5),
            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),
            A.OneOf([
                A.GaussNoise(var_limit=(10.0, 50.0), p=1.0),
                A.GaussianBlur(blur_limit=(3, 7), p=1.0),
            ], p=0.3),
            A.CoarseDropout(max_holes=8, max_height=32, max_width=32, p=0.3),
            A.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225],
            ),
            ToTensorV2(),
        ])
    else:
        return A.Compose([
            A.Resize(img_size, img_size),
            A.HorizontalFlip(p=0.5),
            A.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225],
            ),
            ToTensorV2(),
        ])


def get_valid_transforms(img_size=384):
    """é©—è­‰/æ¸¬è©¦æ™‚çš„è½‰æ›"""
    return A.Compose([
        A.Resize(img_size, img_size),
        A.Normalize(
            mean=[0.485, 0.456, 0.406],
            std=[0.229, 0.224, 0.225],
        ),
        ToTensorV2(),
    ])


def get_tta_transforms(img_size=384):
    """TTA çš„å¤šç¨®è½‰æ›"""
    return [
        # Original
        A.Compose([
            A.Resize(img_size, img_size),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2(),
        ]),
        # Horizontal Flip
        A.Compose([
            A.Resize(img_size, img_size),
            A.HorizontalFlip(p=1.0),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2(),
        ]),
        # Slight rotation
        A.Compose([
            A.Resize(img_size, img_size),
            A.Rotate(limit=10, p=1.0),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2(),
        ]),
        # Brightness adjust
        A.Compose([
            A.Resize(img_size, img_size),
            A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=1.0),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2(),
        ]),
    ]


def merge_train_val_images(config):
    """
    åˆä½µé©—è­‰é›†åœ–ç‰‡åˆ°è¨“ç·´é›†ç›®éŒ„
    é€™æ¨£å¯ä»¥ä½¿ç”¨æ‰€æœ‰è³‡æ–™é€²è¡Œè¨“ç·´
    """
    print("\nğŸ“ æ­£åœ¨åˆä½µè¨“ç·´é›†èˆ‡é©—è­‰é›†åœ–ç‰‡...")
    
    # ç¢ºèªç›®éŒ„å­˜åœ¨
    if not os.path.exists(config.VAL_IMG_DIR):
        print(f"âš ï¸  é©—è­‰é›†ç›®éŒ„ä¸å­˜åœ¨: {config.VAL_IMG_DIR}")
        return False
    
    if not os.path.exists(config.TRAIN_IMG_DIR):
        os.makedirs(config.TRAIN_IMG_DIR)
    
    # å–å¾—é©—è­‰é›†çš„æ‰€æœ‰åœ–ç‰‡
    val_images = [f for f in os.listdir(config.VAL_IMG_DIR) 
                  if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
    
    if len(val_images) == 0:
        print(f"âš ï¸  é©—è­‰é›†ç›®éŒ„ä¸­æ²’æœ‰åœ–ç‰‡")
        return False
    
    copied_count = 0
    for img_name in tqdm(val_images, desc="è¤‡è£½åœ–ç‰‡"):
        src = os.path.join(config.VAL_IMG_DIR, img_name)
        dst = os.path.join(config.TRAIN_IMG_DIR, img_name)
        
        # å¦‚æœç›®æ¨™ä¸å­˜åœ¨æ‰è¤‡è£½
        if not os.path.exists(dst):
            try:
                shutil.copy2(src, dst)
                copied_count += 1
            except Exception as e:
                print(f"âš ï¸  è¤‡è£½ {img_name} å¤±æ•—: {e}")
    
    print(f"âœ“ å®Œæˆï¼è¤‡è£½äº† {copied_count} å¼µåœ–ç‰‡åˆ°è¨“ç·´ç›®éŒ„")
    return True


def create_dataloaders(config, combine_train_val=True):
    """å‰µå»º DataLoaderï¼ˆGPU å„ªåŒ–ç‰ˆï¼‰"""
    train_df = pd.read_csv(config.TRAIN_CSV)
    val_df = pd.read_csv(config.VAL_CSV)
    
    print(f"\nğŸ“Š è³‡æ–™é›†è³‡è¨Š:")
    print(f"è¨“ç·´é›†: {len(train_df)} å¼µ")
    print(f"é©—è­‰é›†: {len(val_df)} å¼µ")
    
    # æª¢æŸ¥é¡åˆ¥åˆ†ä½ˆ
    print("\né¡åˆ¥åˆ†ä½ˆ (è¨“ç·´é›†):")
    for col in config.CLASS_NAMES:
        count = train_df[col].sum()
        print(f"  {col:12s}: {count:4d} ({count/len(train_df)*100:5.1f}%)")
    
    if combine_train_val:
        # åˆä½µåœ–ç‰‡æª”æ¡ˆ
        merge_train_val_images(config)
        
        # åˆä½µ DataFrame
        full_train_df = pd.concat([train_df, val_df], ignore_index=True)
        
        print(f"\nâœ“ åˆä½µå¾Œç¸½æ¨£æœ¬æ•¸: {len(full_train_df)}")
        
        # å‰µå»ºå®Œæ•´è¨“ç·´é›†
        train_dataset = CXRDataset(
            full_train_df,
            config.TRAIN_IMG_DIR,
            transform=get_train_transforms(config.IMG_SIZE, config.USE_ADVANCED_AUG)
        )
        val_dataset = None
        val_loader = None
    else:
        # åˆ†é–‹ä½¿ç”¨è¨“ç·´é›†èˆ‡é©—è­‰é›†
        train_dataset = CXRDataset(
            train_df,
            config.TRAIN_IMG_DIR,
            transform=get_train_transforms(config.IMG_SIZE, config.USE_ADVANCED_AUG)
        )
        
        val_dataset = CXRDataset(
            val_df,
            config.VAL_IMG_DIR,
            transform=get_valid_transforms(config.IMG_SIZE)
        )
        
        val_loader = DataLoader(
            val_dataset,
            batch_size=config.BATCH_SIZE,
            shuffle=False,
            num_workers=config.NUM_WORKERS,
            pin_memory=config.PIN_MEMORY if hasattr(config, 'PIN_MEMORY') else False,
            persistent_workers=True if config.NUM_WORKERS > 0 else False
        )
    
    train_loader = DataLoader(
        train_dataset,
        batch_size=config.BATCH_SIZE,
        shuffle=True,
        num_workers=config.NUM_WORKERS,
        pin_memory=config.PIN_MEMORY if hasattr(config, 'PIN_MEMORY') else False,
        drop_last=True,
        persistent_workers=True if config.NUM_WORKERS > 0 else False
    )
    
    return train_loader, val_loader