import torch
import os

class Config:
    # ==================== GPU è¨­å®š ====================
    # è‡ªå‹•é¸æ“‡æœ€ä½³è¨­å‚™
    if torch.cuda.is_available():
        DEVICE = torch.device('cuda')
        # å¦‚æžœæœ‰å¤šå¼µ GPUï¼Œå¯ä»¥æŒ‡å®šä½¿ç”¨å“ªä¸€å¼µ
        GPU_ID = 0  # ä½¿ç”¨ç¬¬ 0 å¼µ GPUï¼Œå¦‚æžœæœ‰å¤šå¼µå¯ä»¥æ”¹æˆ 1, 2...
        torch.cuda.set_device(GPU_ID)
        print(f"ðŸŽ® ä½¿ç”¨ GPU: {torch.cuda.get_device_name(GPU_ID)}")
    else:
        DEVICE = torch.device('cpu')
        print("âš ï¸  æœªåµæ¸¬åˆ° GPUï¼Œä½¿ç”¨ CPU è¨“ç·´")
    
    # GPU å„ªåŒ–è¨­å®š
    PIN_MEMORY = True if torch.cuda.is_available() else False
    USE_AMP = True if torch.cuda.is_available() else False  # æ··åˆç²¾åº¦è¨“ç·´
    
    # ==================== è·¯å¾‘è¨­å®š ====================
    TRAIN_IMG_DIR = 'train_images'
    VAL_IMG_DIR = 'val_images'
    TEST_IMG_DIR = 'test_images'
    TRAIN_CSV = 'train_data.csv'
    VAL_CSV = 'val_data.csv'
    TEST_SAMPLE_CSV = 'test_data_sample.csv'
    OUTPUT_CSV = 'submission.csv'
    CHECKPOINT_DIR = 'checkpoints'
    
    # ==================== æ¨¡åž‹è¨­å®š ====================
    MODEL_NAME = 'efficientnet_b3'  # å¯é¸: resnet50, efficientnet_b0~b7
    NUM_CLASSES = 4
    IMG_SIZE = 384  # EfficientNet-B3 å»ºè­° 384
    
    # ==================== è¨“ç·´è¨­å®š ====================
    # æ ¹æ“š GPU è¨˜æ†¶é«”èª¿æ•´æ‰¹æ¬¡å¤§å°
    if torch.cuda.is_available():
        # æª¢æŸ¥ GPU è¨˜æ†¶é«”
        total_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        if total_memory >= 24:  # 24GB+ (e.g., RTX 4090, A100)
            BATCH_SIZE = 32
            NUM_WORKERS = 8
        elif total_memory >= 16:  # 16GB+ (e.g., RTX 4080, V100)
            BATCH_SIZE = 24
            NUM_WORKERS = 6
        elif total_memory >= 12:  # 12GB+ (e.g., RTX 3080, RTX 4070)
            BATCH_SIZE = 16
            NUM_WORKERS = 4
        elif total_memory >= 8:   # 8GB+ (e.g., RTX 3070, RTX 4060)
            BATCH_SIZE = 12
            NUM_WORKERS = 4
        else:  # < 8GB (e.g., RTX 3060)
            BATCH_SIZE = 8
            NUM_WORKERS = 2
        print(f"ðŸŽ® GPU è¨˜æ†¶é«”: {total_memory:.1f}GB, æ‰¹æ¬¡å¤§å°: {BATCH_SIZE}")
    else:
        BATCH_SIZE = 4
        NUM_WORKERS = 2
    
    NUM_EPOCHS = 50
    LEARNING_RATE = 1e-4
    WEIGHT_DECAY = 1e-4
    
    # ==================== å„ªåŒ–å™¨è¨­å®š ====================
    OPTIMIZER = 'AdamW'
    SCHEDULER = 'CosineAnnealingLR'
    T_MAX = NUM_EPOCHS
    MIN_LR = 1e-6
    
    # ==================== Early Stopping ====================
    PATIENCE = 10
    
    # ==================== æå¤±å‡½æ•¸ ====================
    USE_FOCAL_LOSS = False
    FOCAL_ALPHA = [1.0, 1.0, 1.0, 1.0]
    FOCAL_GAMMA = 2.0
    
    # ==================== è³‡æ–™å¢žå¼· ====================
    USE_ADVANCED_AUG = True
    
    # ==================== TTA ====================
    USE_TTA = True
    TTA_TRANSFORMS = 4
    
    # ==================== å…¶ä»–è¨­å®š ====================
    SEED = 42
    CLASS_NAMES = ['normal', 'bacteria', 'virus', 'COVID-19']
    
    # Gradient accumulation (å¦‚æžœè¨˜æ†¶é«”ä¸è¶³ï¼Œå¢žåŠ é€™å€‹å€¼)
    ACCUMULATION_STEPS = 1
    
    # æ··åˆç²¾åº¦è¨“ç·´
    USE_AMP = True if torch.cuda.is_available() else False
    
    @staticmethod
    def create_dirs():
        os.makedirs(Config.CHECKPOINT_DIR, exist_ok=True)